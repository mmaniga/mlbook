## Day 1

### The Intuition

Let's structure the overall learning into a form of vina-vidai inspired by the ancient Indian method of learning, where knowledge blossoms through a continuous dance of questions and answers. The old Indian way of learning, where any subject is learned by asking a question, getting an answer and further probing into questions until the teacher and learner come to an agreement that the concept is completely internalized

The answer might be direct, it could also be expressed in the form of asking to observe something else and get the insight by themselves, embracing the idea that true understanding is not just about receiving direct answers but lies in the exploration, observation, and internalization of concepts.

<mark>What is Learning?</mark>

Teaching 1 + 1 = 2  and 2 + 2 = 4  is feeding knowledge to the kids, we teach this for quite some numbers, and after that we ask two sets of questions, asking what is 2+2 and what is 1+1 which was already taught and we see if the kid answers correct, and then we also ask what is 7 + 5 which we would not have thought and if we see the kid answers correctly. If the kid answers correctly for all those additions that are not solved in the class we conclude for most of the unknown numbers we can the kid has learned addition, if the kid has only given the correct answer for already discussed numbers we call the kid has not learned anything but has just memorized the data,  the score the kid gets in solving the unknown problem is a measure of their learning, a 100% mark is 0% error in understanding and we call that as good learning.

The learning here is not just recollecting the solved examples but the ability to run the addition concept, the addition concept is abstract and we expect the kid to use that abstract concept to solve real problems like using fingers and keeping something in mind.

<mark>What is Machine Learning?</mark>

Can machines learn the way humans learn? We now know that they (machines) can't learn the way we humans learn. What we call learning from a machine perspective is the ability of the machine to solve mathematical equations on vast amounts of data. Over the last few centuries, mathematicians have invented special concepts that help in modelling real-world systems by observing them and collecting data about the system and those that affect the system. If we could see the past we could predict the future was the idea behind those creative mathematical fields, they were never called intelligent systems or learning systems but might be called systems that help in modeling data or reasoning out on huge amounts of data.

if we could record the observations and the data we collect have discovered some fundamental mathematical equations using which we can solve lots of problems if we have enough data and the problem falls into a category that the data are related and have some form of co-relation with each other. We will understand about the formulas and how existing mathematics can be used to solve the equation (finding the co-efficient is the right way to say)

<mark>Can Machines learn?</mark>

Yes, if we frame learning from the perspective of what machines are capable of learning. As of today a lot of problems that machine learns is about how to estimate something with less error. That is how we can summarize the entire machine learning aspects. It's all about machines' ability to find a co-efficient of some equation which gives very little error, we will see what the error is and with what respect we call that an error shortly and what equations we are talking about.

<mark>Why should computers learn? Is instruction not enough?</mark>

Reflecting on the essence of computer learning, let's draw a parallel with human learning. Consider this: Why do we learn instead of merely memorizing instructions? The key lies in the ability to tackle new challenges within the same problem space. For instance, if a child learns addition, they can extend that knowledge to solve various addition problems. However, it gets more intriguing. Even though they've mastered addition, they might struggle with multiplication unless explicitly taught. Now, how does this connect to why computers learn?

Computers learn to get answers for unknown inputs within the same problem space. Just like humans, they aim to solve problems they haven't encountered before. Why is this significant? Think about the entire human system—our methods are designed to uncover mathematical equations that perfectly model the problem we are investigating backed by years of data (observations of the system) with the only goal, that is, we can solve the unknown if we have a grasp of the past. We extend this human ability to abstract and predict into computers, empowering them to rapidly compute over vast datasets. The goal? To obtain coefficients for formulas with minimal error, mirroring our human capability to understand relationships among data. So, why should computers learn? **To augment and accelerate our capacity for abstraction and prediction.**

<mark>Let's delve into the concept of learning and instruction. If merely recalling information isn't genuine learning, then does the process of following instructions to arrive at an answer qualify as learning? Specifically, when it comes to learning addition, does it essentially boil down to following a set of instructions?</mark>

Exploring addition, it's challenging to draw a distinct line between learning and following instructions flawlessly. Consider this: a child remembering and correctly solving an "addition" problem—does that signify learning or mastering the art of following complex instructions? Think about the scenario where, instead of recalling 2 + 2, the child invokes an abstract concept, using fingers to count systematically. The steps vary, but the underlying approach remains similar for each input set. Similarly, computers excel at executing instructions. So, the question arises—why not consider computers as learners when they adeptly follow instructions?

<mark>How are instructions different from learning?</mark>

As our discussion deepens, consider another perspective. When we present a problem to a child in straightforward language, like "Ram has 10 chocolates, and Seetha gave him another 13 chocolates," the child must navigate this scenario. The child needs to recognize the need to employ the abstract concept of addition, keeping 10 in mind and counting the additional 13 on fingers to find the answer. In this process, we witness learning, a simpler term for it, where the child understands the need to apply the addition concept based on the instructions.

As we aim to empower computers to solve such problems, the challenge is defining how a computer can learn. ***It's essential to acknowledge that computers don't learn in the same way humans do; just as we didn't create airplanes by mimicking bird flight. Instead, we seek insights into how to define learning for computers, drawing from different scientific perspectives—a realm we humans have understood for a considerable time.***

<mark>I know we are going to learn what learning is and it's going to be a long task but quickly can we understand by an example of what kind of scientific aspect we are going to use for learning and how it is used today outside of computer learning?</mark>

While acknowledging that unravelling the depths of learning will be an extensive journey, let's quickly grasp the essence through an example and understand the scientific aspects involved, applicable not only in computer learning but also in various domains outside the digital realm.

Consider a real-world problem involving house prices and sizes. In a dataset with varying house sizes and prices, the challenge arises when we lack a fixed cost per square foot. Humans have been tackling such problems for ages—imagine predicting the cost of a 1002-square-foot house when the dataset doesn't include that exact size. This is where scientific methods come into play.

In a parallel example, picture a business scenario where we analyze revenue and advertisement spending. Here, a mere lookup won't suffice; we need to discern the impact on revenue for a unit change in spending. This leads us to delve into linear regression in mathematics—a concept we'll explore later. In essence, this mathematical technique helps us find the formula representing changes in revenue concerning alterations in advertisement spending.

In both instances, the shift in perspective towards understanding the relationship between variables, be it house sizes or business parameters, unveils the scientific methods humans have been using for prediction. Humans have traditionally employed mathematical tools to predict unknowns using known data. In this context, rather than directly determining the cost per square foot, we ask a different question: How does a change in one square foot affect the price? This shift in perspective led to the invention of abstract knowledge, utilizing tools like regression to identify the rate of change and whether it's constant or variable.

While humans historically didn't explicitly term this process as "learning," today, as we bring computers into the equation, we use this term (learning) to describe the representation of abstract concepts. Computers, by finding coefficients for formulas, mimic (actually assist) the human ability to create equations that can predict outcomes. What was once an inherent part of human problem-solving is now labeled as learning in the realm of computers. We'll delve deeper into these concepts as our exploration unfolds.

<mark>Unveiling the Power of Graphs and Equations in Understanding Relations, let's explore the idea further. When we plot data points on a graph, each point represents an intersection of variables—such as x for advertisement spending or house area in square feet and y for revenue or house price. Now, the question arises: can we simply connect these dots to form a line or a graph, or is there more to it?</mark>

Yes, we can't merely connect dots manually, especially in real-world scenarios with numerous data points. What we aim for is to discover an equation for a line that accurately represents the relationship between x and y.

Yes, indeed. Picture this in simple terms: while in school, we might have connected dots to form a line, but in real-world scenarios, it's not as straightforward. With numerous data points, connecting every dot with a single line is impractical. We turn to mathematical models, specifically lines that go close to the maximum number of points or encompass the maximum number. This line, a representation of the relation between x and y, becomes our choice for understanding the dynamics.

In essence, a line's continuity allows us to find its slope, indicating the rate of change. What emerges is a prediction engine. Historically, we didn't explicitly term this a prediction engine; instead, it was considered a model representing the relation between two entities. It's not a mere lookup table; it's an equation, such as y = 10x + 2. In this example, for every dollar spent on advertisement, roughly $12 is generated in revenue, and if no funds are allocated to advertising, $2 is the expected revenue. This equation is the model. Computers excel at determining the values (10 and 2) through regression, marking the foundation of machine learning, a concept we'll delve deeper into as our exploration continues.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708534715993/2bf6178c-4684-483c-be15-8e2980b19672.png align="center")

Graph depicting a simple linear relation (taken from Wikipedia)

<mark>Human Guidance in Formulating Equations for Computer Learning. Let's clarify a crucial aspect. Did the computer independently choose to use the y = mx + c equation to generalize the problem, or was this formula provided by humans, the computer simply discovering that y = 10x + 2 best fits the given data? That is, the computer found out the value of m and b for the above equation in a really large dataset impossible for humans to find.</mark>

Precisely. The computer doesn't autonomously decide on the abstraction to use. In the current state of machine learning, humans encode formulas like

$$y = mx + c$$

into computer programs, guiding the computer on how to perform regression through programming.

The mathematical calculations, involving concepts like derivatives (which we'll explore later), are handled by humans outside the computer. The computer follows instructions, executing the logic programmed by humans to find the values for **m** and **b** in the abstract equation—essentially, determining the rate of change and the intercept from the data.

This process is conventional programming, with mathematical logic handled externally. Once the computer obtains these values, **m** and **b**, it transforms into a model or prediction engine, exhibiting behaviour akin to a learned system. While the initial steps involve programming and logic, once armed with the model, the computer operates in a manner akin to a learned system, adapting to new data inputs by readjusting its parameters.

<s>Unveiling the Essence of Mathematical Abstraction and Learning System.</s>

<mark>Let me encapsulate my comprehension. Humans have identified specific mathematical abstractions that, when applied thoughtfully, effectively depict relationships within specific domains. We've crafted intricate abstractions, simplifying them into mathematical equations suitable for computer application. As the computer executes these programs with input data, it generates a model—an actual value for an abstract equation. For end-users, this model embodies a learned system; for creators, it signifies advanced computer programming, and for users, it manifests as a learning engine.</mark>

Accurate. Over centuries, we've harnessed mathematical inventions initially crafted to understand the rate of change and system behaviour concerning alterations in parameters. When viewed through a learning lens, the rate of change becomes a pathway for prediction. Experimenting with one variable while keeping others constant, originally designed for system observation, transforms into a means of predicting unknown values. What originated as tools for system observation has evolved into algorithms for learning, ultimately contributing to the development of machine learning systems, culminating in entities like ChatGPT. We'll delve deeply into each mathematical abstraction and explore how each incrementally contributes to constructing learning systems and machine learning frameworks.

Conclusion and Pondering for Future Sessions

Today, we navigated through the intricate realm of learning, drawing parallels between human and computer learning processes. We grasped the concept of mathematical abstractions, their translation into equations, and how computers, following human-encoded instructions, create models for predictions. As we journeyed through the evolution from system observation to predictive learning, we laid the groundwork for understanding machine learning systems.

Key Takeaways:

1. Learning Paradigm: Learning involves the intricate dance of abstract concepts, mathematical abstractions, and the creation of models for predictions.
    
2. Human-Computer Symbiosis: While computers follow instructions and generate models, it's crucial to recognize the guidance and programming provided by humans in this process.
    
3. Mathematical Abstractions: Centuries of mathematical inventions designed for system observation have transformed into the building blocks for predictive learning, driving the development of machine learning systems.
    

Pondering for Future Sessions:

1. Understanding Mathematical Abstractions: How do various mathematical abstractions contribute incrementally to the construction of learning systems?
    
2. Evolution of Learning Algorithms: What insights can we glean from the historical evolution of learning algorithms, and how do they shape the landscape of machine learning today?
    
3. Human and Machine Learning Synergies: How can the synergies between human-guided programming and machine learning algorithms be optimized for enhanced learning capabilities?
    
4. Application in Real-World Scenarios: What are the practical implications of these learning concepts in solving complex real-world problems, and how can they be further refined?
    

These questions set the stage for our future explorations into the fascinating world of learning and machine intelligence.

## Day - 2

If prediction is learning then why have we never called weather prediction a learning system or AI system? If I am right, weather prediction involves some complex mathematical modelling techniques and also works on past data to arrive at predicting the future given the necessary inputs about the future.

I would expect you to come up with your answer as we progress along with other questions.

<mark>I believe, now I comprehend the machine's perspective on learning, particularly how machines represent abstract concepts through mathematical functions (formulas), with a model encapsulating the coefficients for these equations. The essence of answering the unknown lies in leveraging the rate of change to predict values for unknowns. I'm eager to explore how these foundational concepts can be applied to construct advanced machine-learning systems, such as book recommendations or cat identification in images.</mark>

Your understanding is mostly correct. However, it's crucial to acknowledge that we are currently exploring the basics of machine learning to avoid complicating our initial knowledge building. In essence, machine learning involves finding coefficients for the given formula

$$y = mx + c$$

from the available dataset, adjusting the coefficients with new insights, and using the model to answer new questions. It's worth noting that abstraction, like

$$y = mx + c$$

can be employed to build various models, each suitable for answering questions within its specific domain. Human intervention is required to determine which abstraction is apt for a given problem space (at least for now, keeping that assumption).

<mark>Regarding your inquiry about how simple models can perform complex tasks like book recommendations or cat identification, we will delve into these concepts in more detail as we progress.</mark>

To provide a brief response, even complex machine learning, at its core, relies on simple AND and NAND gates. Similarly, the basic abstraction of regression serves as the foundation for all machine learning, with various forms of linear and logistic regression combining to address intricate machine learning problems.

<mark>How should we proceed from this juncture? Is a foundational understanding of mathematics a prerequisite, or can I learn gradually?</mark>

Your question is perceptive, drawing parallels to the way children learn to walk by first running. Similarly, we'll delve into specific details before tackling the fundamentals, adopting an iterative approach to learning concepts and revisiting basics. We've explored the essence of learning from a mathematical perspective, emphasizing how correctly applied mathematical methods grant machines the supposed superpower of prediction.

Prediction, a mathematical method with a history spanning at least 300 years, captivates mathematicians seeking to understand how one variable changes concerning another. The quest is to identify the "magic number" enabling the discovery of unknowns using known data. For instance, when presented with historical data on house prices with area in square feet and price in Rupees, how do we formulate a function predicting price based on square footage?

The function's correctness is established by predicting the correct answer (or close to correct) for existing data. Confidence in this function's ability to predict unknown or future input arises from its accurate predictions for known data. Acknowledging the potential for error (deviation between expected and predicted values), we prioritize functions with minimal error when predicting existing data.

A basic relationship between two variables is expressed as y = x, signifying that its values are always x, resulting in a straight line when graphed. However, real-life relations are more intricate, like

$$y = 2x$$

$$y = 2.3x + 10$$

$$y = -3.3x + 3$$

Mathematicians seek to establish ***y*** as a function of ***x***, aiming for a value of ***y*** that remains true or nearly true indefinitely.

If this intuition resonates, we'll delve further into exploring how to establish linear relations between a known (independent variable) and an unknown (dependent variable), unravelling the magic numbers of slope and intercept.

Before delving into estimating the slope and intercept, it's pivotal to recognize the fundamental equation representing a line

$$y = mx + c$$

While we won't extensively explore its origin to avoid delving into advanced algebra, a basic comprehension is assumed. If you're familiar with plotting x and y data on a graph to discern linear relations, we can smoothly progress.

The next step involves directly understanding linear regression. We've established that regression aids in finding the unknown based on the known. Now, let's develop an intuition about regression and work through the math behind it to understand how we derive the magic numbers for m and b—essentially, how we arrive at a regression line for a given dataset.

The intuition behind linear regression is as follows: we observe data and identify a relation between variables. Our data is not random; it comprises one or more independent variables (e.g., size of a house, garden size, number of car parking spaces) and exactly one dependent variable (the answer, conclusion, such as house price or expected revenue).

For a simple regression, the data can be plotted using a line equation like

$$y = mx + c$$

where ***m*** is the slope and ***c*** is the intercept. When we plot the data on a graph, we initially see only points, not a line. The line is what regression helps us find, at this point, we know there would be a line (our prediction line), that, when plotted, accurately predicts historic and future data with minimal error.

The graph would initially appear as a collection of points. After the regression, we'd have found a line, the regression line, which when drawn on the same graph accurately predicts values. The regression line wasn't present when we plotted the original data.

The graph would be like this initially

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708535735867/87a1529d-1654-49ff-8ef0-3d36ed945a57.png align="center")

From here after regression, we would have found a line which when drawn on the same graph would be like this

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708535755466/c2bff467-cd38-4c89-8adf-7cabc5f3a430.png align="center")

It's crucial not to be misled by the graph. To reiterate, the regression line wasn't there initially; regression helps us find it. While there are various methods to obtain this line, once finalized, this line minimizes errors (the difference between predicted and expected values) for each existing value. In essence, every prediction, when compared with existing values, has less error than any other line we might have chosen.

This blue line is the regression line, the prediction, this line is the one we have to find, this line was not there when we plotted the original data.

We should not be misguided by seeing the graph, let me re-iterate, the line was not there to start, the regression found this line, there are many ways to get this line, but this line once finalized would be the line that has minimal error (the difference between predicted vs expected) for each of the existing value. To state it one more time, for this line, every prediction when compared with the existing value would be less than any other line we might have chosen.

Imagine if we had chosen a line like the red line; the difference between predicted and actual values would be significantly higher compared to the blue line.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708535842190/f4d59098-1279-4534-b5e2-8b6424fd70a2.png align="center")

<mark>The regression purpose is to get this blue line instead of a red line and how it achieves is what we are going to look further.</mark>

Certainly, I appreciate your progress in grasping regression concepts. Let's transition to a more abstract discussion without relying heavily on examples or analogies.

In the context of a given dataset exhibiting linear relations, the linear equation

$$y = mx + c$$

becomes a valuable tool for modelling data. While the linear relation between x and y is apparent, the underlying rate of change (relation) is not explicitly known. The continuity is evident, but the precise pattern for obtaining ***y*** for a given ***x*** remains elusive. The key element to determine in this scenario is the slope, as it represents the rate of change. Once the rate of change (slope) is identified, the line can be drawn.

Regression, in essence, revolves around determining the rate of change from the data to model it into a line. Consider this graph, we established the necessity of

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708535946119/651c9d26-5814-4500-8489-6696b8cd1765.png align="center")

drawing a line, referred to as the prediction engine. The line's continuous nature enables the prediction of ***y*** for any given ***x***. It can be termed a model, learning engine, prediction mechanism, or logic, but essentially, it boils down to finding the equation of a line, such as

$$y = 2x + 3$$

The process of arriving at this formula involves no magic. In a simplified scenario without advanced mathematical concepts, one might resort to an old-school approach: experiment, document results, check for correctness or acceptability, and repeat until expected results are achieved. In practical terms, this could mean drawing lines at random, computing errors, documenting the outcomes, and iterating until an acceptable line is found.

Assume we decide to experiment with 10,000 lines, sorting them based on error, and selecting the line with the least error as the regression line out of the 10,000 possibilities.

While this intuition provides a straightforward understanding, the correct method for finding the regression line involves more sophisticated mathematical frameworks to enhance efficiency and accuracy

<mark>If I summarize my understanding, we have data to start with, that data exhibit linear relations, we need to find the line that best represents the data, so we pick up a line at random with some guessed value for m and b, for that line compute the total error, that is, for each x computer its error in prediction, that is, the difference between actual y and predicted y,&nbsp; (from the line we just made predicted_y = random_mean * actual_x + random+b), error = y - predicted_y, do like this do for some 10,000 lines, choose the line with lowest error, that line is the regression line.</mark>

<mark>The experiment we did helped us find a line that best captures the relation between x and y with minimal error for all existing values of x concerning the existing y value, that is, for every x the corresponding Y would have very little deviation from the original value of y and hence this line is best, it re-enforces that no other line would give least error for every known data in the dataset. If my understanding is correct, can you now further explain the details of how exactly it's done?</mark>

Good Understanding, you have comprehended how the overall logic of getting the best line is done, though this intuition is correct it's not exactly correct unless you ask further questions like how the second line got drawn, the third line,  and so on, that is, we start with some random value of m and b, how do we update the value of m and b and on what basis, is It random or it's done with some logic, asking such question would make sure the intuition you build is very good and not at a superficial level.

I would like to state the assumptions you made with some pictorial representation to help you reinforce the knowledge better.

### Day -3

Is it true that without data, machine intelligence cannot exist? I'll leave this question for contemplation over the next few days and return with a comprehensive write-up.

Computer intelligence primarily operates through regression. In other words, we assist computers in constructing models, which they subsequently utilize for making predictions.

Today, our focus will be on grasping the mechanics of linear regression.

We've outlined the essential steps for understanding how machines predict using linear regression, why it's employed, and how it accomplishes predictions. As I've mentioned earlier, let's take a brisk pace in our learning journey. For today, we'll delve into the intuition, algorithm, and coding aspects, visually witnessing how linear regression can be put into action. We aim to convert our intuition into a practical solution.

To simplify the learning process without undermining its essence, we'll tackle linear regression using straightforward data. We'll work with just three points, making it easier to visualize and manually compute the regression while verifying the outcomes.

Intuition and abstraction shouldn't impede our understanding of the system's intricacies.

Let's consider the dataset we'll analyze:

| X | Y |
| --- | --- |
| 1 | 1 |
| 2 | 3 |
| 3 | 2 |

This dataset is elementary. We'll visually inspect the data to confirm its linear relationship and explore in detail how a line can represent this data.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708720504635/c606d673-0618-441d-9872-827d3d9eb681.png align="center")

To translate our intuition into code, we can adopt two approaches. The first one is a brute-force method, where we draw around 10,000 lines and select the one with the least error. This approach serves to illustrate that amidst numerous lines, one will be the most fitting, and our task is to identify it using mathematical abstractions (rather than using the brute force approach).

The graph below provides a glimpse of the brute-force approach, with 50 iterations displayed. The blue lines represent lines generated during the iterations, while the final line, chosen based on minimal error, is highlighted in red.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708720533440/cf46337e-dca3-4e25-ad46-a92aa68c3226.png align="center")

In the previous session, we learned about another method called Stochastic Gradient Descent (SGD). In this approach, we begin with initial estimates of m and b, create a line, compute its error, and then adjust m and b to generate the next line. We repeat this process iteratively, refining m and b in each iteration until we arrive at the final line that best fits the data.

The graph below illustrates the iterations of this method, condensed into 10 steps for simplicity. The dark black line represents the final line, with its slope and intercept defining the relationship between x and y. This line exhibits minimal error about our experiment, making it the optimal choice for prediction.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708720572966/c1b1539d-6988-48f9-bf3b-b01e3f9c84a5.png align="center")

A word of caution: We're simplifying many steps here, opting for the most basic approach without utilizing advanced mathematics. Even high school-level math isn't employed in this approach, as you'll notice when we examine the code.

By directly coding our intuition, we aim to internalize the concept first. As we progress, we'll encounter more advanced mathematical concepts, primarily aimed at achieving higher accuracy with less computation.

Please conduct a thorough exploration of the concepts with the aid of fully functional code.

**Linear Regression - Brute Force Approach**

```python
import numpy as np
import matplotlib.pyplot as plt

# Data points
data = np.array([(1, 1), (2, 3), (3, 2)])
X = data[:, 0]
Y = data[:, 1]

# Function to calculate the total squared error for a line
def calculate_total_squared_error(m, b, X, Y):
    return np.sum((Y - (m * X + b))**2)

# Run brute force approach for 50 iterations
iterations_bf = 50
lines_bf = []

for _ in range(iterations_bf):
    m_random = np.random.randn()
    b_random = np.random.randn()
    error = calculate_total_squared_error(m_random, b_random, X, Y)
    lines_bf.append((m_random, b_random, error))

# Sort the lines by error and select the best one
best_line_bf = sorted(lines_bf, key=lambda line: line[2])[0]
best_m_bf, best_b_bf, best_error_bf = best_line_bf

# Plot the data points
plt.scatter(X, Y, color='blue', label='Data Points')

# Plot each line generated by brute force in blue
for m, b, _ in lines_bf:
    plt.plot(X, m * X + b, color='blue', alpha=0.3)

# Highlight the best line in red
plt.plot(X, best_m_bf * X + best_b_bf, color='red', label='Best Fit Line', linewidth=2)

# Plot configuration
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Brute Force Regression Lines with Best Fit Highlighted')
plt.legend()
plt.show()

# Output the best line parameters
print(f"Best fit line parameters: Slope (m) = {best_m_bf:.4f}, Intercept (b) = {best_b_bf:.4f}")
```

**Linear Regression -** Stochastic Gradient Descent (SGD)

```python
import numpy as np
import matplotlib.pyplot as plt

# Define the data points
X = np.array([1, 2, 3])
Y = np.array([1, 3, 2])

# Initial guess for m and b
m = 0.0
b = 0.0

# Learning rate
learning_rate = 0.01

# Function to calculate the total squared error
def total_squared_error(m, b, X, Y):
    total_error = 0.0
    for i in range(len(X)):
        y_pred = m * X[i] + b
        total_error += (Y[i] - y_pred) ** 2
    return total_error

# Function to adjust m and b heuristically
def adjust_m_b(m, b, X, Y, learning_rate):
    # Try adjusting m up and down, see which direction reduces error
    error_before = total_squared_error(m, b, X, Y)
    m_adjusted_up = total_squared_error(m + learning_rate, b, X, Y)
    m_adjusted_down = total_squared_error(m - learning_rate, b, X, Y)
    
    # Update m based on which direction reduced error
    if m_adjusted_up < error_before:
        m += learning_rate
    elif m_adjusted_down < error_before:
        m -= learning_rate
    
    # Do the same for b
    b_adjusted_up = total_squared_error(m, b + learning_rate, X, Y)
    b_adjusted_down = total_squared_error(m, b - learning_rate, X, Y)
    
    if b_adjusted_up < error_before:
        b += learning_rate
    elif b_adjusted_down < error_before:
        b -= learning_rate
    
    return m, b

# Perform iterations
iterations = 10
for _ in range(iterations):
    m, b = adjust_m_b(m, b, X, Y, learning_rate)

# Plot the final line
plt.scatter(X, Y, color='blue', label='Data points')
y_pred = m * X + b
plt.plot(X, y_pred, color='red', label='Adjusted line')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Adjusted Line without Using Partial Derivatives')
plt.legend()
plt.show()

print(f"Adjusted values without using partial derivatives: m = {m:.4f}, b = {b:.4f}")
```

### Day - 4

Let's dive into the code and explore the math behind it, including why we're doing certain calculations, how we adjust *m* and *b*, the reasoning behind these adjustments, and why advanced math is necessary.

Before we examine the program, let's outline the steps to solve the problem using both the brute force approach and the Stochastic gradient approach, and then we'll move on to the code.

<mark>What exactly are we trying to do here?</mark>

We're aiming to find the slope of a straight line and its intercept.

<mark>But why is it hard to find the slope of the line when we already have its formula as </mark> *<mark>y</mark>*<mark>=</mark>*<mark>m</mark>*<mark>∗</mark>*<mark>x</mark>*<mark>+</mark>*<mark>c</mark>*<mark>?</mark>

<mark>A good question. So, what values do </mark> *<mark>m</mark>* <mark> and </mark> *<mark>b</mark>* <mark> hold, and how do we figure them out? It may sound simple, but where do we get these values from?</mark>

One suggestion might be to plot the data and check the graph.

However, there's a crucial point to consider: when we plot the data, we see scattered points, not a continuous line. Each point represents where *x* and *y* intersect, but we can't just connect any two points to make a line.

<mark><br>Why is it not possible to simply connect the dots to form a line?</mark>

The reason is that the dots on a scatter plot are not arranged in a contiguous manner. Typically, a scatter plot would resemble something like this.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1708896973188/6acee532-76ac-48fb-bcb0-4839a3749147.png align="center")

How do you determine which points to connect to form a straight line?

<mark><br>Why can't I simply draw a line in the middle and consider it the best line?</mark>

While it's a reasonable assumption, determining what makes a line the best choice requires a specific criterion. Additionally, how can a computer replicate this process, considering that we as humans can visually inspect the data and draw a line?

<mark>Can you explain why I need to establish a line?</mark>

It's essential to review the previous sessions to grasp the significance of this. By now, you should have a solid understanding of the context surrounding this problem. In simple terms, we aim to create a model based on the data. As humans, when we observe the data, we intuitively envision a straight line that intersects those data points. This line serves as a representation of the data, enabling us to make predictions about future outcomes. To ensure the reliability of our predictions, we need to verify that this line accurately predicts past data, which can be easily validated. However, since the line cannot pass through every data point, there will be some errors in predicting past data. This error, defined as the difference between the expected and predicted values, needs to be minimized. Therefore, we seek a line that minimizes this error across all past data points. This rationale clarifies the necessity of establishing a line and highlights the desired properties of that line.

<mark>How do you determine the line?</mark>

To initiate the process, can I opt for a random line?

<mark>Certainly, but how exactly do you generate a random line?</mark>

Allow me to speculate. As humans, we typically draw a line by connecting dots. Alternatively, if we're provided with a line formula like Y = 2\*x + 2, we can choose values for x within a certain range, compute the corresponding values of Y, plot these points, and then draw the line connecting them.

<mark>Are we going to perform that task here? Can you identify the source of the equation y = 2*x + 2? We only possess data and the general equation of a line, namely y = mx + c.</mark>

Alright, I understand now. I'll focus on determining the values of m and b rather than x and y. Since x and y are already known, the missing information lies in m and b. So, I'll start by guessing values for m and b and then proceed to draw a line based on those values.

<mark>You're spot on. After drawing the line based on the guessed values of m and b, what's your next step in this approach?</mark>

I need to calculate the error for this line and maintain information about both the line and its error.

<mark>Excellent. You've highlighted two key tasks: computing the error and storing the details of this line along with its error. Now, how do you propose representing this line?</mark>

Combining m, b, and the error would provide a comprehensive representation of the line. I could store these values in a hash table, map, or similar data structure, with m and b serving as the key and the error as the corresponding value.

<mark>And how do you plan to calculate the error for a line?</mark>

With the given values of m, b, and the dataset, I would compute the error using the following approach: for each x, y data point, I'll calculate the predicted y value based on the line equation y = mx + b.

<mark>You're correct, but did you overlook mentioning the necessity of iterating over the entire dataset?</mark>

Here's how it works: to compute the error, I assume specific values for m and b, and then for each {x, y} pair, I calculate the error. This involves applying the equation y = m \* x\[i\] + b to predict the y value. Subsequently, I calculate the error as the difference between the predicted y and the actual y. This process repeats for every data point, with the errors being accumulated.

In essence, for a given set of m and b values, we determine the total error by assessing the error it generates with each existing data point relative to the actual y value. This cumulative error is then stored.

Following that, we iterate through this process with new m and b values, typically for a considerable number of iterations, such as 10,000 times. Each iteration produces a new line along with its corresponding error.

By the end of these iterations, we have a collection of 10,000 lines, each associated with its respective error. This allows us to compare and evaluate the performance of different combinations of m and b.

<mark>Now, could you elaborate on what comes next in this process?</mark>

Certainly! Here's a simple algorithmic overview of the process:

1. **Initialize**: Begin by randomly selecting values for m and b.
    
2. **Iterate**: Repeat the following steps for a predetermined number of iterations (e.g., 10,000):
    
    * a. **Compute Error**: For each {x, y} pair in the dataset:
        
        * i. Predict the y value using the equation y = m \* x + b.
            
        * ii. Calculate the error as the difference between the predicted y and the actual y.
            
        * iii. Accumulate the error across all data points.
            
    * b. **Update Model**: Save the current values of m, b, and the total error.
        
    * c. **Generate New Line**: Randomly choose new values for m and b.
        
3. **Select Best Fit**: Identify the line with the smallest total error from all iterations.
    
4. **Finalize Model**: Declare this line as the best-fit model or prediction line.
    
5. **Use for Prediction**: Utilize this line for making further predictions based on new input data.
    

This algorithm outlines the iterative process of finding the best-fit line by repeatedly adjusting the parameters m and b, computing errors, and selecting the line with minimal total error.

<mark>Good, can you write the code in simple steps, and explain the code with proper comments?</mark>

Certainly! Here's a breakdown of the algorithm steps along with the corresponding code snippets:

1. **Define the Dataset**:
    
    * Summary: Define the dataset containing the data points (x, y).
        
    
    ```python
    # Define the dataset
    data = np.array([(1, 1), (2, 3), (3, 2)], dtype=[('x', float), ('y', float)])
    ```
    
2. **Set the Number of Iterations**:
    
    * Summary: Specify the number of iterations for the algorithm to generate random lines and calculate errors.
        
    
    ```python
    # Set the number of iterations
    iterations = 10
    ```
    
3. **Calculate the Total Squared Error for a Line**:
    
    * Summary: Define a function to compute the total squared error for a given line.
        
    
    ```python
    # Function to calculate total squared error for a line
    def calculate_total_squared_error(m, b, data):
        total_error = 0
        for point in data:
            x, y = point
            guess = m * x + b
            total_error += (y - guess) ** 2
        return total_error
    ```
    
4. **Generate Lines with Random Slopes and Intercepts**:
    
    * Summary: Generate multiple lines with random slopes (m) and intercepts (b) and compute their total errors.
        
    
    ```python
    # Generate lines with random slopes and intercepts, calculate error
    lines_and_errors = []
    for _ in range(iterations):
        m = np.random.randn()
        b = np.random.randn()
        error = calculate_total_squared_error(m, b, data)
        lines_and_errors.append([m, b, error])
    ```
    
5. **Sort Lines by Error in Ascending Order**:
    
    * Summary: Sort the generated lines based on their total errors in ascending order.
        
    
    ```python
    # Sort lines by error in ascending order
    for i in range(len(lines_and_errors)):
        for j in range(i + 1, len(lines_and_errors)):
            if lines_and_errors[i][2] > lines_and_errors[j][2]:
                lines_and_errors[i], lines_and_errors[j] = lines_and_errors[j], lines_and_errors[i]
    ```
    
6. **Select the Line with the Least Error**:
    
    * Summary: Select the line with the least error from the sorted list.
        
    
    ```python
    # Select the line with the least error
    best_line = lines_and_errors[0]
    best_m, best_b, _ = best_line
    ```
    
7. **Plot Data Points and Best Line**:
    
    * Summary: Plot the data points and the best-fit line obtained from the algorithm.
        
    
    ```python
    # Plot data points
    plt.scatter(data['x'], data['y'], color='blue', label='Data points')
    
    # Plot the best line
    plt.plot(data['x'], best_m * data['x'] + best_b, color='red', label='Best line')
    
    # Show the plot
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Best Line from Randomly Generated Lines')
    plt.legend()
    plt.show()
    ```
    
8. **Output the Best Line's Parameters**:
    
    * Summary: Display the parameters (slope and intercept) of the best-fit line.
        
    
    ```python
    # Output the best line's parameters
    print(f"Best line parameters: m = {best_m:.4f}, b = {best_b:.4f}")
    ```
    

These steps outline the algorithm's process of generating and evaluating multiple lines to find the best-fit line for the given dataset.

<mark><br>Can you please explain the intuition behind the implementation and the drawbacks of this implementation?</mark>

The brute force method operates on the principle of probability, leveraging the law of large numbers to find a satisfactory fit. By generating numerous random lines and evaluating their performance, there's a higher chance that one of these lines will closely match the underlying relationship between the variables x and y. However, while this approach may yield satisfactory results, it comes with significant drawbacks.

Firstly, it's computationally expensive, as it involves generating and evaluating a large number of lines, which can be time-consuming and resource-intensive. Additionally, this method is inefficient since it doesn't utilize any prior knowledge or information about the dataset. Instead, it relies solely on random chance to stumble upon a suitable solution. Consequently, there's no guarantee of finding the optimal or most accurate fit, and the process may yield suboptimal results compared to more targeted or informed approaches.

<mark><br>Can you explain the logic behind the error function and tell me why are you summing the error with the entire dataset?</mark>

The logic behind the error function is to quantify how well a given line, represented by its slope *m* and intercept *b*, fits the dataset. The error function calculates the difference between the actual *y* values in the dataset and the predicted *y* values generated by the line for each corresponding *x* value. This difference is squared to ensure that both positive and negative errors contribute equally to the overall error calculation. The squared errors are then summed across all data points to obtain the total squared error for the line.

Summing the error across the entire dataset is necessary to assess the overall performance of the line in fitting the data. By considering the collective error across all data points, we get a comprehensive measure of how well the line captures the underlying relationship between *x* and *y*. This approach allows us to evaluate the line's performance holistically rather than focusing on individual data points. Additionally, summing the errors provides a single metric that can be compared across different lines, facilitating the selection of the line with the lowest total error as the best fit for the dataset.

<mark>Allow me to introduce two new concepts: stochastic and gradient. We'll delve into how these concepts pave the way for advancing our algorithm to create a more sophisticated model.</mark>

### Day - 5

By now, I trust that the fundamental concepts have been firmly established as we delve into a more detailed session involving some mathematics that may have slipped from memory or remained dormant since high school. Before we proceed, let me pose a couple of questions: Why is it not advisable to utilize the brute force approach to resolve the regression problem? Can the algorithm be enhanced, and if not, what are the limitations preventing its improvement?

At times, our progress may be hindered unless we acquire new skills. Regardless of our efforts, our skill level may act as a limiting factor. Therefore, we find ourselves at a juncture where introducing new skills or perspectives in our thinking becomes imperative for further advancement.

Building upon our previous session, let's delve into two new concepts: Stochastic and Gradient. We'll explore what they entail and how they contribute to computation in general, as well as how they are applied to compute linear regression.

The term "Stochastic" denotes randomness or uncertainty, often involving probabilities. In its mathematical context, it refers to a process that involves deriving a sequence of values from a sequence of random variables.

At this juncture, you might question why our brute force algorithm isn't categorized as stochastic. The answer warrants a deeper exploration, but I invite you to contemplate one crucial aspect: while the brute force approach entails randomness and guesswork at each step, it lacks feedback between successive steps. Essentially, each of the 10,000 attempts aims to strike luck with a single-shot guess, akin to banking on lottery tickets for success. Mathematicians tend to eschew pure randomness unless it exhibits a form of convergence, wherein feedback plays a pivotal role. In our upcoming algorithms, we'll introduce constant feedback mechanisms, wherein each step contributes incrementally towards the solution space. Although our initial guess may be random, immediate feedback informs us of our proximity to the solution space and guides subsequent corrective steps. This iterative process, driven by intuition and encapsulated in the learning rate, continues until an acceptable solution is achieved.

<mark>Before delving into the gradient, let's address the randomness in the code. We should modify the code to eliminate blind randomness and introduce a feedback mechanism that leverages the error function to adjust the feedback.</mark>

Sure, let me explore the idea. You're suggesting that instead of waiting until the end to evaluate errors and choose the best line, we could incorporate error evaluation into each iteration. This means considering the error at every step of trying different m and b combinations and using that error to guide the selection of m and b. We should develop a strategy to adjust m and b using error as a feedback mechanism.

<mark>I see your difficulty in conceptualizing the solution. Let me offer an analogy: Imagine you're maneuvering a large piece of furniture up a narrow staircase. You don't just try to lift it straight up. Instead, you adjust its position little by little, nudging it this way and that to navigate around obstacles. Each adjustment brings you closer to your goal without bumping into walls or railings. Applying this analogy to our problem can help us approach it more effectively.</mark>

I believe I understand now. In each iteration, I can make slight adjustments to the values of m and b. However, I'm unsure about the criteria for making these adjustments and how much they should be. Additionally, I'm uncertain about the direction or trajectory I should be aiming for with these adjustments.

<mark>It's excellent that you're approaching the problem with such insight. However, have you considered the significance of the error function we've defined? Specifically, have you thought about why we square the error values?</mark>

Squaring the error helps standardize its representation by ensuring that all error values are positive. This uniformity facilitates clearer analysis and interpretation of the error, aiding in the overall understanding of the model's performance.

<mark>If we don't square the error we would have the error as positive or negative, what insight does the positive or negative value of the error provide about the line created.</mark>

Let me consider this. The error is calculated as

Error = *Y*− Predicted\_Y.

So, if the Predicted\_Y is greater than the actual Y, we obtain a negative error, indicating that we've overshot. Conversely, if the Predicted\_Y is less than Y, we get a positive error, suggesting that we are falling short of the actual value.

<mark>You're on the right track with your analysis. Now, let's delve a bit deeper. After reaching this conclusion, what's the subsequent course of action? What steps will you take based on this understanding?</mark>

I've been contemplating how to adjust *m* and *b* based on the error. My initial, albeit somewhat blind, idea is to increment the values of *m* and *b* by a small factor if the error is positive and decrement them if the error is negative. However, I must admit, that this approach lacks a thorough understanding, and I'm merely grasping at ideas without fully comprehending the underlying principles.

<mark>You are indeed correct. Allow me to explain why that logic might work.</mark>

Let's work on a signal data point to show just the logic of adjusting m, let m = 0 and the graph would be like this. In this example, let's assume that the actual value of *y* is 1.5 for *x* = 2, the predicted value is 3, and our initial guess for slope *m* is 0 (represented by the red line).

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709064366752/75905a1c-09a8-45ef-8abc-b29e56fec3fc.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709064393262/123f72d3-810f-4095-aef0-c7de80b8daae.png align="center")

Now, what change in *m* can you make so that the value of *y* gets closer to 1.5 while keeping everything else the same, meaning the *x* value is not changed and the *c* value (to keep it simple, in real programming we will change the value of c as well) is not changed?

Let's decrease the value of m and see what happens in the graph.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709064636182/0c86f7ca-12e7-4727-8d48-8dd2ce5291b1.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709064686084/c5d47f77-eed3-4f36-bd31-a4e1b68e906b.png align="center")

As we decrease *m*, the line progressively approaches the actual *y* values. Notably, incrementing *m* in positive values directs it toward the x-axis, while decrementing it moves it closer to the y-axis. Thus, based on the error, we refine the slope of the line either positively or negatively. This experiment underscores that modelling the data as a line enables us to refine the value of *m*, yielding a more accurate representation of the data with minimized overall error. Ultimately, this experiment emphasizes the iterative process of adjusting *m* and *b* until an acceptable solution is achieved.

Let's visually walk through the example of getting a correct line for the following data

| X | Y |
| --- | --- |
| 1 | 1 |
| 2 | 3 |
| 3 | 2 |

Let's compute the linear regression using Wolfram Alpha for the following data

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709063232639/00974ac4-080f-417f-a05d-313edfe0730a.png align="center")

Let's now visually do the linear regression using the above-mentioned method and verify if our approach gives the correct result.

Initially let's take m = 0 and c = 0

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709063646159/9b912cde-eb9e-4b57-9450-c73285e8becf.png align="center")

We increment the m and b by a very small amount like this and see the graph, at this point, the error is 14.0.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709065329494/ddd556a6-412a-4e13-b481-8e3fb27df40d.png align="center")

During the second iteration, the error is around 13.0 and the m and b are adjusted to 0.02, let's see the graph ( I am scaling the graph for visual representation)

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709065658640/6ca674f2-0c4e-4513-8a43-edc2faf1a405.png align="center")

Continuing in this manner, we will reach this point in the graph

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709065723045/593c705a-82ca-4975-a874-c8f5e69f36f9.png align="center")

The value of m is what is close to what Wolfram Alpha also predicted, this is the second method of getting the regression line. Now let's deep dive into the algorithm formally and deep dive into the code step by step.

Have you considered that if you square the error you lose the ability to adjust, what is your solution to this problem?

&lt;Write a detailed answer&gt;

<mark>Now that you have acquired a detailed understanding of the concepts, would you please proceed to comprehend the code thoroughly and explain the algorithm, the intuition behind it, and the code itself in detail?</mark>

The provided code implements a heuristic approach to linear regression without using gradient descent or any derivative-based optimization method. Here's a detailed explanation of the algorithm, its intuition, the code, the drawbacks of not using derivatives, and an in-depth look at the error function and its role in adjusting the values of *m* (slope) and *b* (y-intercept).

### **Algorithm Overview**

1. **Initialize Parameters**: Start with initial guesses for the slope (*m*) and y-intercept (*c*) of the linear regression line. Typically, these are set to 0.
    
2. **Define the Error Function**: Use the total squared error function to measure the accuracy of the regression line. This function calculates the square of differences between the predicted *y* values and actual *y* values, summing them up for all data points.
    
3. **Adjust Parameters Heuristically**: In each iteration, adjust *m* and *b* slightly up or down, determining which direction reduces the total squared error. Repeat this process for a fixed number of iterations or until the error stops decreasing significantly.
    
4. **Plot and Analyze Results**: After the final iteration, plot the regression line along with the data points to visualize the fit. Print the final values of *m* and *b*.
    

### **Intuition Behind the Algorithm**

The core idea is to find the line that best fits the data points by minimizing the error between the predicted values and the actual values. The algorithm tries to find the values of m and b that minimize the total squared error between the actual data points and the predicted points using a heuristic approach. By adjusting m and b in small increments and decrements, and observing the change in the total squared error, it moves towards the direction that reduces the error. This process is repeated iteratively until a satisfactory solution is found or the maximum number of iterations is reached.

### **Detailed Code Explanation**

* **Initial Guess**: *m* and *b* are initially set to 0, indicating a horizontal line at the y-axis origin.
    
* **Total Squared Error Calculation**: `total_squared_error` function calculates the sum of squared errors by iterating over the data points, computing the predicted y-value using the current m and b, and summing the squared differences between the actual and predicted y-values.
    
* The error function used in this code is the total squared error, which is the sum of squared differences between the actual y-values (Y) and the predicted y-values (y\_pred) for all data points. It is calculated as
    
* ```javascript
          total_error = Σ (y - y_pred)^2
    ```
    
    where y is the actual y-value and y\_pred is the predicted y-value using the current values of m and b.
    
* The reason for using the squared error is that it penalizes larger errors more heavily than smaller errors, which helps the algorithm focus on reducing the most significant errors first.
    
* The values of m and b are adjusted in the `adjust_m_b` function based on the change in the total squared error. The function calculates the total squared error before any adjustments (`error_before`). Then, it tries adjusting m by `learning_rate` in both positive and negative directions and calculates the corresponding total squared errors (`m_adjusted_up` and `m_adjusted_down`). If either of these errors is smaller than `error_before`, it updates m in the direction that reduces the error.
    
* Similarly, the function tries adjusting b by `learning_rate` in both positive and negative directions and calculates the corresponding total squared errors (`b_adjusted_up` and `b_adjusted_down`). If either of these errors is smaller than `error_before`, it updates b in the direction that reduces the error.
    
* The reason for adjusting m and b in this manner is to move them towards the values that minimize the total squared error. By trying small increments and decrements and observing the change in the error, the algorithm can determine the direction in which to update m and b to reduce the error.
    
* **Adjustment Logic**: `adjust_m_b` tries adjusting *m* and *b* both up and down by a small learning rate. It then observes which direction leads to a lower error and updates *m* and *b* in that direction.
    
    * First, it calculates the total squared error before any adjustments.
        
    * Then, it tries adjusting m by `learning_rate` in both positive and negative directions and calculates the corresponding total squared errors.
        
    * It updates m in the direction that reduces the error (if any).
        
    * Similarly, it tries adjusting b by `learning_rate` in both positive and negative directions and updates b in the direction that reduces the error (if any).
        
    * Finally, it returns the updated values of m and b.
        
* To explain the intuition behind the adjustment logic:
    
    * If the total squared error decreases when m is increased slightly, it means that the slope of the line is too small, and we need a steeper slope to fit our data better. Therefore, m is incremented by the learning rate.
        
    * Conversely, if the total squared error decreases when m is decreased, it means the slope is too steep, and we need to make it flatter to fit our data better. Therefore, m is decremented by the learning rate.
        
    * The same logic applies to the intercept b; if the error decreases when b is increased, then b is too small, and we increase it. If the error decreases when b is decreased, then b is too large, and we decrease it.
        
    
    This process is repeated iteratively, adjusting m and b in small steps in the direction that reduces the total squared error, which is a measure of how well the line fits the data points. The learning rate determines the size of these steps. The goal is to find the values of m and b that minimize the total squared error, which would mean the line fits the data as closely as possible given the model. ​
    
* **Iterative Optimization**: The process repeats for a predetermined number of iterations, progressively reducing the error by fine-tuning *m* and *b*.
    

Let's break down the code into its core components and explain each part with the relevant code snippets.

### **1\. Initialize Parameters**

The first step is initializing the slope (`m`) and y-intercept (`b`) of the line. These parameters define the line that we will adjust to fit our data points.

```python
codem = 0.0
b = 0.0
```

### **2\. Define the Error Function**

The total squared error function calculates how well our line fits the data. It measures the sum of the squares of the differences between the predicted values and the actual values (`Y[i]`).

```python
def total_squared_error(m, b, X, Y):
    total_error = 0.0
    for i in range(len(X)):
        y_pred = m * X[i] + b
        total_error += (Y[i] - y_pred) ** 2
    return total_error
```

### **3\. Adjust Parameters Heuristically**

This function adjusts `m` and `b` to minimize the total squared error. It tries increasing and decreasing `m` and `b` by a small `learning_rate` and observes whether the error decreases. If it does, the adjustment is kept; otherwise, it's reverted.

```python
def adjust_m_b(m, b, X, Y, learning_rate):
    error_before = total_squared_error(m, b, X, Y)
    # Adjusting m
    m_adjusted_up = total_squared_error(m + learning_rate, b, X, Y)
    m_adjusted_down = total_squared_error(m - learning_rate, b, X, Y)
    if m_adjusted_up < error_before:
        m += learning_rate
    elif m_adjusted_down < error_before:
        m -= learning_rate
    # Adjusting b
    b_adjusted_up = total_squared_error(m, b + learning_rate, X, Y)
    b_adjusted_down = total_squared_error(m, b - learning_rate, X, Y)
    if b_adjusted_up < error_before:
        b += learning_rate
    elif b_adjusted_down < error_before:
        b -= learning_rate
    return m, b
```

### **4\. Perform Iterations**

The loop below performs the adjustments for a set number of iterations. In each iteration, it calls `adjust_m_b` to tweak `m` and `b` in an attempt to reduce the error.

```python
iterations = 10
for _ in range(iterations):
    m, b = adjust_m_b(m, b, X, Y, learning_rate)
```

### **5\. Plot the Final Line**

After adjusting `m` and `b`, the final line is plotted along with the data points. This visual representation helps to understand how well the line fits the data.

```python
plt.scatter(X, Y, color='blue', label='Data points')
y_pred = m * X + b
plt.plot(X, y_pred, color='red', label='Adjusted line')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Adjusted Line without Using Partial Derivatives')
plt.legend()
plt.show()
```

### **Conclusion and Drawbacks**

This code illustrates a basic approach to linear regression without using derivatives. It incrementally adjusts `m` and `b` based on trial and error, seeking to reduce the total squared error. However, this method lacks the precision and efficiency of gradient descent, which uses derivatives to directly compute the direction and magnitude of the needed adjustments for `m` and `b`. The absence of a derivative-based approach means this algorithm may take longer to converge and might not reach the optimal solution, especially for complex datasets or when the initial guess is far from the optimal values.

### Day - 6

Let's summarize our understanding so far.

In the context of linear regression, we want to find the best values of the slope (m) and the y-intercept (b) that make the line

$$y=mx+b$$

fit the given data points (X, Y) as closely as possible. This "closeness" or "goodness of fit" is typically measured by an error/cost function, which quantifies how far the predicted values (y\_pred) are from the actual values (y).

The error function we use is the sum of squared errors, which calculates the squared difference between the predicted and actual values for each data point, and then sums them up.

Going forward, we will pay more attention to the cost/error function. This error function is a mathematical formula that includes both m and b. Changing m and b also changes the error value. We aim to find the m and b values that minimize the error, ideally achieving the lowest possible error.

This cost function represents how well our linear model (the line) fits the actual data points. We want to find the line (defined by its slope and intercept) that fits the data as closely as possible. The cost function gives us a way to measure how "good" or "bad" a particular line is at fitting the data.

We have the intuition and visual representation of how to view this line and data points, to reiterate it here, imagine you have a set of data points on a graph, and you want to draw a line that goes through or near those points. You can draw many different lines, each with a different slope and intercept. For each line you draw, you can calculate how far away it is from each data point. The cost function takes all those distances (called residuals) and adds them up in a specific way (by squaring them and then summing) for each line.

A good line will have a small cost function value (error) because its residuals (distances from the data points) are small. A bad line will have a large cost function value (error) because its residuals are large. Our goal is to find the line that has the smallest possible cost function value – this is the line that fits the data best.

We have done two approaches so far to get the good line, one is through blind guess, that is, we randomly draw multiple lines and select the line with the least error, the second approach is similar but we have some heuristics and we adjusted m and b based on feedback and continuously improved to find a good line. In both these approaches, our goal was to find the line that has the least error.

So far, we have focused on adjusting m and b. Moving forward, our attention will shift to the cost function. As we continue, we will intuitively understand why we made this shift and how calculus is applied to this problem. We will try to grasp how it works and review the concepts behind its effectiveness as we progress.

Before we move on, let's take a moment to focus on another aspect of our data. Up, until now, we've looked at the data, the values of m and b, and the line they create, but we haven't paid much attention to visualizing the error itself. Let's start visualizing the error in relation to m and b. We adjust m and b, based on the error, this means we can also plot this error against m and b (in a 3d space). A high error value will appear as a spike, and a low value will dip down. In machine learning, this is often compared to visualizing hills and valleys.

Now, to visualize this concept, imagine the cost function as a three-dimensional surface (or landscape). The surface represents all possible combinations of the slope and intercept parameters (the x and y axes). The height of the surface at any point (m, b) is the value(error) of the cost function for that particular slope and intercept.

This surface will have peaks and valleys. The peaks represent lines (slope and intercept combinations) that fit the data poorly, so they have high-cost function values. The valleys represent lines that fit the data well, so they have low-cost function values.

We aim to locate the lowest point on this surface – where the cost function is at its minimum, representing the best combination of slope and intercept for the most accurate line fit.

If you've followed along, you'll understand that plotting the square error against m and b shows us we should choose the m and b where the error is lowest. **This means the line represented by these values will have the least error compared to all data points, making it the best-fit line**. However, we arrive at this conclusion by looking at the value(error) of the cost function. This insight shifts our focus to the cost function, and we'll use additional mathematical concepts to approach and understand this cost function from a mathematical perspective.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1709839574384/bf2ca7f6-8a79-4532-aa70-87336f8006fe.png align="center")

Before we get into the details, make sure you understand three key aspects: mean square error, and the parameters m and b, by visualizing them. I've also highlighted the point where we identify the minimum error. The x in the graph indicates the (error) value of the cost function corresponding to m and b.

<mark>Thank you for the detailed summary. Now I understand that moving forward, our focus will be on this cost function. We'll approach it as a function as we do in mathematics and view it as an optimization problem to find the minimum. You'll introduce some mathematical concepts that I'll understand as we progress. The goal is to understand how it works, and later, you'll explain why it works that way.</mark>

Understood, let's approach this step-by-step, we'll focus on visualizing the cost function and understanding how it relates to the errors or residuals for different values of m and b.

<mark>Okay, so we want to find the values of m and b that minimize the cost function, the error represents the overall deviation from the actual data points. Instead of adjusting m and b based on the value of the cost function each time, can we leverage the cost function in some way?</mark>

That's an excellent idea. Let's think of the cost function as a three-dimensional surface or landscape, where the x and y axes represent the values of m and b, respectively, and the z-axis represents the value of this cost function for each combination of m and b.

Imagine this landscape is having peaks and valleys. The peaks correspond to combinations of m and b where the value of this cost function is large, indicating a poor fit to the data. The valleys represent combinations of m and b where the value of this cost function is small, indicating a good fit.

Our goal is to find the lowest point on this landscape, which corresponds to the values of m and b that give us the absolute minimum cost function value, and therefore, the best fit to the data.

<mark>I see, visualizing the cost function as a 3D surface makes a lot of sense. The lowest point on this surface would represent the optimal values of m and b that we're trying to find.</mark>

<mark>But how do we find this lowest point? If we try to visualize the surface, it might be difficult to pinpoint the exact minimum, and we cannot employ inspecting visually as a solution to any problem.</mark>

You're right. Visualizing the surface can help in understanding the concept, but it might not be practical or accurate enough to find the exact minimum point.

This is where we introduce a systematic and mathematical approach to find the minimum point of the cost function surface rather than exhaustively searching the entire surface.

<mark>Can you state the cost function mathematically?</mark>

Of course, the cost function can be represented mathematically as follows:

$$cost = yActual - yPredicted$$

Where:

* *y*Actual​ represents the actual value of *y* for a given data point.
    
* *y*Predicted​ represents the predicted value of *y* based on our model.
    

This formula calculates the difference between the actual and predicted value of *y* for each data point, allowing us to quantify the error associated with our model's predictions.

Let's break it down further,

For a given data point, let's denote *Y* as the actual value corresponding to a certain *x*, and the predicted value as

$$mx+b$$

where *m* and *b* represent the slope and y-intercept, respectively, and the error is the difference between the expected and the predicted value, which we subsequently square to emphasize its significance (are we progress you will intuitively understand why we square).

This process is repeated for each data point. In essence, we iterate through all data points for a specific combination of *m* and *b*, calculating the error for each point and accumulating these squared errors. This aggregation results in the sum of squared errors, providing us with a comprehensive measure of the model's performance across all data points.

In summary, the cost function encapsulates this iterative process, allowing us to evaluate the overall effectiveness of our model in capturing the relationships between variables.

<mark>Excellent, could you express the cost function in mathematical terms? As we proceed, we'll be delving into a considerable amount of mathematical analysis.</mark>

Of course, here's a more concise representation using mathematical symbols:

$$yPredicted = mx+b$$

$$error = (y - yPredicted)^2$$

substituting yPredicted with mx + b

$$error = (y - (mx + b)) ^2$$

$$totalError = 0$$

$$foreach(dataPoints): error = (y-yPredicted)^2: totalError += error$$

$$(y - (mx+b))^2$$

<mark>Good, can you please express this as a proper mathematical formula using the math symbol, you have given it like a pseudo code?</mark>

Sure, here is the proper mathematical way to express the cost function

$$\text{Cost Function} = \sum_{i=1}^{n} (y_i - (mx_i + b))^2$$

In this formula:

* *n* represents the number of data points.
    
* (*xi*, *yi*​) are the coordinates of the *i'th* data point.
    
* *m* and *b* are the slope and intercept parameters of the linear model, respectively.
    
* ∑ denotes the summation over all data points, and
    

$$(y - (mx+b))^2$$

* calculates the squared error for the data point.
    

Excellent, as we progress our focus deals with this cost function

$$\text{Cost Function} = \sum_{i=1}^{n}(y_i -(mx_i + b))^2$$

<mark>Is this cost function alone sufficient for us to progress further?</mark>

No, while we can interpret the cost function as providing insight into the error associated with each combination of *m* and *b*, it solely furnishes this information without offering a method to identify optimal *m* and *b* values. Visually plotting the cost function may provide some clarity, but it does not offer a systematic approach to pinpointing the minimum. We require a more sophisticated strategy to navigate this cost function and determine the most favourable *m* and *b* values without exhaustively searching the entire parameter space.

The challenge lies in the fact, that the cost function alone lacks sufficient detail to guide us towards its minimum point. While it provides the cost for specific *m* and *b* values, it fails to prescribe the adjustments necessary to minimize the cost function. This is the focus of further study, on how to leverage cost function to finalize the m and b. <s>Thus, we must employ additional mathematical techniques or draw upon our existing mathematical knowledge to address this problem effectively.</s>

<mark>Are you implying that the intuition I've developed, which involves calculating the error for a predicted </mark> *<mark>m</mark>* <mark> and adjusting </mark> *<mark>m</mark>* <mark> and </mark> *<mark>b</mark>* <mark> to minimize this error, won't be relevant as we move forward?</mark>

No, that's not accurate. Those intuitions will be incredibly valuable. As we tackle more complex problems ahead, we'll need to formalize these intuitive concepts quantitatively (in a measurable way), and that's where calculus becomes essential. We'll continue to rely on the same intuition, but now with the assistance of calculus.

In this context of machine learning, we approach the cost function as an entity that we aim to minimize (find the value of m and b which gives the least value for this function). This function is complex because it's dependent on multiple variables—specifically, the parameters *m* (slope) and *b* (intercept) in the case of linear regression.

The goal is to find the values of m and b that minimize the cost function (getting the smallest value), resulting in the best-fit line that minimizes the difference between the predicted and actual values.

We delve deeper into the topic as we go further, here's a brief overview of our approach before we get started in its depth.

Gradient descent is an iterative optimization algorithm that we will employ to minimize the cost function. The core idea behind this technique is to update the values of the parameters *m* and *b* by moving in the opposite direction of their respective gradients (partial derivatives) with respect to the cost function. The gradient represents the rate of change of the cost function with respect to each parameter, indicating the direction of the steepest ascent. If this concept seems overwhelming at first, don't worry; we will delve into it in greater detail later. In simpler terms, our goal is to derive two formulas based on the cost function that will determine the rate at which *m* and *b* should be adjusted. Since our objective is to find the minimum value of the cost function, we need to move in the direction opposite to the gradient, hence the term "descent." By iteratively updating *m* and *b* using these formulas, we will gradually converge towards the optimal values that minimize the cost function. It's important to note that the gradient represents the increasing rate of change, and by moving in the opposite direction, we aim to decrease the cost function and approach its minimum value.

Calculus, particularly derivative calculus, plays a crucial role in transforming the Mean Squared Error (MSE) formula into two distinct derivatives—one for *m* and one for *b*. These derivatives offer insights into the rate of change of the cost function concerning adjustments in *m* and *b*, providing valuable perspectives on optimizing(minimizing) the function.

The partial derivatives of the cost function concerning *m* and *b* are:

$$\begin{equation} \begin{aligned} \frac{\partial}{\partial m} &= \frac{2}{N} \sum_{i=1}^{N} -x_i(y_i - (mx_i + b)) \\\\ \frac{\partial}{\partial b} &= \frac{2}{N} \sum_{i=1}^{N} -(y_i - (mx_i + b)) \end{aligned} \end{equation}$$

These derivatives guide us in adjusting *m* and *b* to minimize the cost function, i.e., the Mean Squared Error (MSE). Here's the analytical expression for these derivatives.

***Note Mani: - I forgot to write about the analytical expression of the derivatives***

These partial derivatives serve as indicators of the "gradient" or multidimensional slope of the cost function. The gradient typically points towards the direction of the steepest ascent, indicating where the function increases most rapidly. However, since our objective is to minimize the Mean Squared Error (MSE), we update the parameters *m* and *b* in the opposite direction of the gradient. This approach is known as gradient descent.

By iteratively adjusting *m* and *b* with this method, each step taken represents a calculated experiment that brings us closer to the "bottom" of the cost function. This "bottom" corresponds to the point where the function reaches its minimum, indicating the smallest possible error.

Therefore, in each iteration, new values of *m* and *b* are computed, gradually reducing the steepness or gradient, aiming for a state where the slope of the cost function is zero or minimal, corresponding to a flat surface and minimal error. This iterative process persists until the adjustments to *m* and *b* yield no substantial change in MSE, signifying either the optimal values have been attained or that we have reached the closest approximation to zero error within the model's capability.

Intuitively, the term

$$x_i(y_i−(mx_i+b))$$

in the partial derivative with respect to m gives more weight (please pay more attention to this weight, that is, why we are multiplying the error with x) to the error (the difference between actual and predicted values) based on the value of x. This means that larger errors at higher values of x have a more significant impact on the slope m. Similarly, the error term for b reflects the discrepancy between our prediction and the actual value without considering the influence of x.

In summary, our gradient approach harnesses calculus principles to steer the optimization process. It transcends mere trial and error by strategically moving in a direction determined by the calculated rate of error reduction, thereby utilizing mathematical tools to enhance the predictive capabilities of our model.

<mark>I feel this method you mentioned is almost similar to mean squared error using the heuristic approach, am I correct in my assumption?</mark>

These formulas can be considered as slight modifications of the MSE formula:

The MSE function calculates the average of the squared errors across all data points.

The derivatives reflect the average rate at which the MSE changes with a small change in m or b, but instead of squaring the error, we're interested in the direction of the error to adjust our parameters.

The -ve sign is crucial: it tells us that if the slope of the cost function with respect to m or b is positive, we need to decrease m or b to move towards a minimum, and vice versa.

In summary, the cost function quantifies the error between the predicted and actual values. The gradients ( for m and b which we will explore as we proceed further) are computed using calculus and represent the rates of change of the cost function concerning m and b, respectively. The gradient descent algorithm uses these gradients to iteratively update the values of m and b in the direction that minimizes the cost function, ultimately finding the best-fit line that models the relationship between x and y in the training data.

Thus far, the concepts we've grasped remain highly relevant; we'll continue building upon them incrementally, harnessing mathematical principles to refine the algorithm further.

### Day 7

Today, our focus will be on implementing the gradient descent algorithm that we discussed previously. We'll write a Python code to execute this algorithm and go through it step by step. After this, we'll delve into a thorough understanding of the mathematical concepts involved.

We will be working on these two equations, one for m and one for b

$$\begin{equation} \begin{aligned} \frac{\partial}{\partial m} &= \frac{2}{N} \sum_{i=1}^{N} -x_i(y_i - (mx_i + b)) \\\\ \frac{\partial}{\partial b} &= \frac{2}{N} \sum_{i=1}^{N} -(y_i - (mx_i + b)) \end{aligned} \end{equation}$$

First I will explain how we got to these two equation given that we only know about the cost function and we also understood that cost function by itself cannot help in finding the minimal value of m and b. Let's do a a step-wise breakdown of these math equation into a workable formula.

**Derivative for m**:

Sure, let's start by understanding the intuition behind this formula. Then, we'll break down the cost function step by step to arrive at this final equation.

$$\frac{\partial}{\partial m} = \frac{2}{N} \sum_{i=1}^{N} -x_i(y_i - (mx_i + b)) \\\\$$

**The Intuition Behind the Gradient Formula for *m*:**

1. **Error Calculation**:
    
    * For each point in our dataset, we calculate the difference between the actual output *yi*​ and our line's predicted output *mxi*​+*b*. This difference is known as the error. If *yi*​ is higher than our prediction, the error is positive; if it's lower, the error is negative.
        
2. **Weighting the Error**:
    
    * We then multiply each error by its corresponding input value, *xi*​. This step "weights" the error. Why? Because it reflects the impact of each data point on the slope of the line. Data points further away from the origin (having a higher *xi*​) will have a more significant influence on the slope *m* of the line.
        
3. **Summing the Weighted Errors**:
    
    * After weighting each error, we sum them up. This sum represents the total weighted error across all data points. By considering all the errors together, we get a comprehensive measure of how well our line fits the data.
        
4. **Scaling the Sum**:
    
    * We scale this sum by 2/*N*​. Why 2? This comes from the derivative of the squared error, which you'll see in calculus as part of the power rule. The *N* in the denominator averages the total error, which standardizes it regardless of the number of data points, preventing the total error from being too large just because there are many points.
        
5. **Negative Sign and Steepest Descent**:
    
    * The negative sign in front of the formula is crucial. It tells us that to reduce the error (to descend), we need to move in the opposite direction of the positive gradient we've calculated. If the sum of weighted errors is positive, we need to decrease *m* to reduce the total error; if it's negative, we need to increase *m*.
        

**Derivative for b**:

$$\frac{\partial}{\partial b} = \frac{2}{N} \sum_{i=1}^{N} -(y_i - (mx_i + b))$$

Let's dissect the intuition behind the gradient formula for *b*, the y-intercept in linear regression, following a similar structure to the explanation for *m*. The derivative calculation for *b*, the y-intercept, involves summing the errors across all data points, similar to the process for *m*, but with a key difference in how these errors are treated.

**The Intuition Behind the Gradient Formula for *b*:**

1. **Error Calculation**:
    
    * Just as with *m*, we calculate the error for each data point as the difference between the actual output *yi*​ and the predicted output *mxi*​+*b*. This error tells us how far off our prediction is for each point.
        
2. **The Role of *b* in Predictions**:
    
    * The y-intercept *b* represents where our line crosses the Y-axis, essentially setting the baseline output **when all *xi*​ values are zero**. Unlike *m*, which scales the prediction according to *xi*​, *b* adjusts the prediction uniformly, regardless of the value of *xi*​.
        
    * In a linear regression model, *b* represents the y-intercept of the regression line, which is the point where the line crosses the y-axis. The value of *b* determines the vertical position of the line on the graph. Adjusting *b* shifts the line up or down without changing its slope. This means that changes to *b* affect the predictions uniformly across all values of *xi*​, which is different from the slope *m* that affects predictions based on the magnitude of *xi*​.
        
3. **Summing the Errors**:
    
    * Similar to the process for *m*, we calculate the error for each data point as the difference between the actual output *yi*​ and the predicted output (*mxi*​+*b*). We sum these errors across all data points. However, unlike the process for *m*, we do not weight these errors by *xi*​ when calculating the derivative for *b*. This is because the y-intercept *b* shifts the entire line up or down on the graph uniformly, affecting all points equally regardless of their *xi*​ values. This uniform impact means the sum of errors gives us a total measure of how much and in which direction (up or down) the line's y-intercept needs to adjust to minimize the overall error.
        
4. **Scaling the Sum**:
    
    * This sum is also scaled by \*N/\*2​. The factor of 2 is consistent with the derivative of the squared term from calculus, and dividing by *N* averages the error across all points.
        
5. **Negative Sign and Direction of Adjustment**:
    
    * The presence of the negative sign indicates that we adjust *b* in the opposite direction of the gradient to reduce the error. If the sum of errors is positive, indicating our predictions are generally below the actual values, we need to increase *b* to lift the line upwards. Conversely, if the sum is negative, indicating our predictions are above the actual values, we decrease *b* to lower the line.
        

**Why the Derivative of *b* Is Similar to *m*:**

* The formulas for the derivatives with respect to *m* and *b* share a similar structure because both parameters directly influence the line's fit to the data. The primary difference lies in how they impact the prediction: *m* scales with *xi*​ (hence the multiplication by *xi*​ in its formula), while *b* shifts the prediction up or down uniformly (reflected by the absence of *xi*​ in its formula).
    
* The scaling factor difference (the presence or absence of *xi*​) stems from their roles in the linear equation *y*\=*mx*+*b*. The slope *m* determines how steeply the line rises or falls as *x* changes, requiring consideration of *xi*​ when calculating its gradient. In contrast, *b* sets the starting point of the line on the Y-axis, affecting all points equally, which is why *xi*​ doesn't factor into its gradient calculation.
    

**Additional Insights:**

* **Adjusting *b***: The y-intercept *b* in the linear equation *y*\=*mx*+*b* determines where the line crosses the y-axis. When you adjust *b*, you are moving the line up (increasing *b*) or down (decreasing *b*) parallel to its original position. This adjustment does not affect the line's slope *m*, which means the angle at which the line tilts remains unchanged.
    
* **Uniform Impact on Predictions**: Because the line's slope remains unchanged when adjusting *b*, the change in predicted *y* values due to an adjustment in *b* is the same for all *xi*​ values. For example, if *b* is increased by 1 unit, all predicted *y* values will increase by 1 unit, regardless of their corresponding *xi*​ value. **This uniformity contrasts with changes to the slope *m*, which have a differential impact on predicted *y* values depending on *xi*​.**
    
* **Contrast with Adjusting *m***: The slope *m* determines how steep the line is. Adjusting *m* changes the angle of the line, affecting predicted *y* values in a way that depends on *xi*​. A higher *xi*​ value means a larger change in the predicted *y* value for a given change in *m*, reflecting the interaction between *m* and *xi*​ in the equation *y*\=*mx*+*b*.
    

In summary, the process to adjust *b* parallels that for *m* but focuses on uniform adjustments to the line's position rather than changes in its slope. This uniformity explains why the derivative's calculation is simpler, lacking the weighting by *xi*​ present in the derivative for *m*.

**Understanding MSE and the partial derivatives**

Now let's shift our focus towards understanding, the cost function from which the above two were derived

$$\text{MSE} = \frac {1}{N} \sum_{i=i}^N (y_i - (mx_i + b))^2$$

We have discussed in the past that to minimize this cost function, we need to know how it changes with respect to the parameters *m* and *b*. This is where derivatives come in. We take the derivative of the MSE with respect to *m* and *b* as shown above.

I am going to give a very high-level overview of this derivation process, the details of this derivation will be understood in detail as we progress, here, my focus is to give you a working formula.

**Let's derivate for m**

When you differentiate the squared term

$$(y_i -(mx_i + b))^2$$

We want to take the derivative of this term with respect to *m*, which will give us an expression for the gradient of the cost function with respect to *m*. This gradient will tell us how to change *m* to minimize the cost function.

We apply the power rule first. The power rule states that if you have a function

$$f(x) = x^n$$

then the derivative with respect to x is

$$f'(x)=nx^{n-1}$$

Another way to read is like this, the differentiation step using the power rule

$$\frac{d}{dx}[x^n] = n \cdot x^{(n-1)}$$

So, applying the power rule to our squared term we get the following.

$$\frac{\partial}{\partial m}(y_i -(mx_i +b))^2 = 2(y_i -(mx_i + b))^{2-1}$$

When simplified, it reads like this

$$2(y_i - (mx_i + b))$$

Now it does not stop here, we need to work on the inner term, that is, we have the second part, which is the derivative of the inner function

$$(y_i - (mx_i + b))$$

with respect to *m*. To make it more clear, the way we can visualize in two parts like this

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1710223759176/73f54bae-5c89-4c3d-bf60-dd743fc51f77.png align="center")

We use the chain rule here because we're differentiating a function of a function (a composite function). The chain rule tells us to take the derivative of the outer function and multiply it by the derivative of the inner function.

That is, the derivative of this inner function

$$y_i-(mx_i +b)$$

If you pay attention, this is part of the squared error function and the part inside the bracket is the simple linear equation y = mx+b.

This is a simple linear equation y = mx+b, and we want to find out how a small change in *m* would affect this function. When we differentiate this equation with respect to *m*, *yi*​ is a constant (it does not depend on *m*), so its derivative is 0.

Let's break down the derivative:

*yi*​ is a constant as far as the differentiation with respect to *m* is concerned. The derivative of a constant is 0.

When differentiating −*mxi*​, we treat *xi*​ as a constant because *xi*​ is the input and is not changing with *m*. So the derivative of *m* multiplied by a constant (−*xi*​) is simply that constant (−*xi*​).

The derivative of *b* with respect to *m* is 0 because *b* does not change with *m*; it's a constant in this context.

So, applying the differentiation, we get

$$\frac{\partial}{\partial m}[y_i] = 0$$

since yi is constant

$$\frac{\partial}{\partial m}[-mx_i] = -x_i$$

(applying the power rule, the derivative of *m* is 1, and we keep the −*xi*​ as is)

$$\frac{\partial}{\partial m}[-b] = 0$$

(since *b* is a constant with respect to *m*)

Adding these up, we get:

$$\begin{equation} \begin{aligned} = 0 - (-x_i) - 0& \\ = x_i \end{aligned} \end{equation}$$

But since we have a negative sign already in front of *mxi*​ in the original function

$$y_i - (mx_i + b)$$

when we differentiate it, the negative sign gets carried over, making it −*xi*.

To summarize:

* The derivative of a constant is zero.
    
* The derivative of *m* with respect to *m* is 1, so when multiplied by *xi*​, it becomes *xi*​.
    
* Since the term *mxi*​ was subtracted in the original function, it contributes a negative sign upon differentiation.
    

Combing the outer and inner we get the final formula, that is, when we put it all together, we multiply the derivative of the outer function by the derivative of the inner function, which gives us:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1710224870439/e753076e-2bcd-4ddb-b200-50593f699117.png align="center")

This final expression gives us the gradient of the cost function with respect to *m* for a single data point. The negative sign in −*xi*​ is because when you take the derivative of −*mxi*​ with respect to *m*, you're left with −*xi*​. This negative sign is important as it tells us the direction of the slope of the tangent line to the curve at that point, indicating how we should change *m* to decrease the cost function.

To rewrite this function to make it simple for coding, it will be presented in the following form.

$$\frac{\partial}{\partial_m}[y_i - (mx_i+b))^2] = 2\cdot(y_i - (mx_i+n))\cdot(-x_i)$$

which can be written as

$$-2\cdot x_i \cdot (y_i -(mx_i+b))$$

This term tells us how the error changes for a small change in *m*. The −2 is crucial because it ensures that we move in the opposite direction of the increase of the cost function (since we want to minimize it). If the error is positive (meaning our prediction is below the actual value), multiplying by −2 will make the adjustments to move upwards. If the error is negative (meaning our prediction is above the actual value), multiplying by −2 will make the adjustments to move downwards.

The final formula for the m derivative that we can use in code would be in the following form.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1710237598202/d3a7d984-b291-46ed-b041-5b956ab4402c.png align="center")

If we recap on the intuition, now it becomes clear, take the sum of the product of the errors and the corresponding *x* values and then average it over the number of observations (denoted by *N*).

Here's what each part represents:

* *xi*​ is the ith feature value.
    
* *yi*​ is the ith actual target value.
    
* *m* is the current estimated slope.
    
* *b* is the current estimated intercept.
    
* *N* is the total number of observations.
    

The -2 coefficient comes from the power rule when taking the derivative of the squared error, and the sum aggregates the contribution of each individual error across all observations. The division by *N* then averages this sum, which is part of calculating the mean squared error.

**Let's derivate with respect to b**

Now let's understand with respect to b, the cost function remains the same. To minimize this cost function, we need to know how changes in *b* affect the error. We find this out by taking the derivative of the MSE with respect to *b*, which gives us the gradient with respect to *b*.

So, applying the power rule to our squared term we get the following.

$$\frac{\partial}{\partial b}(y_i-(mx_i+b))^2 = 2(y_i-(mx_i+b))^{2-1}$$

When simplified, it reads like this

$$2(y_i-(mx_i+b))$$

Now it does not stop here, we need to work on the inner term, that is, we have the second part, which is the derivative of the inner function, but this time we are going to do with respect to b.

For the derivative of the inner function (*yi*​−(*mxi*​+*b*)) with respect to *b*,*yi*​ and *mxi*​ are constants (as they do not depend on *b*) and the derivative of a constant is zero. The derivative of −*b* with respect to *b* is −1 because if *b* changes by 1 unit, the term −*b* changes by -1 unit.

$$\frac{\partial}{\partial b}[y_i-(mx_i+b)] = -1$$

Combining the two parts that is the outer squared and the inner one, the 2 from the power rule and the -1 from the derivative of the inner function will multiply together, and the expression simplifies to:

$$= -2 \cdot \sum_{i=1}^N (y_i - (mx_i + b))$$

In the MSE function, there's a 1/*N*​ coefficient in front, which we apply when taking the derivative. This gives us the final gradient for *b*, averaging the sum of errors:

$$= \frac {-2}{N} \cdot \sum_{i=1}^N (y_i - (mx_i + b))$$

This is the gradient with respect to *b*, and it tells us the direction to adjust *b* in order to minimize the MSE. If *the* derivative​ is positive, it means that increasing *b* would increase the error, so we need to decrease *b* to reduce the error. Conversely, if the derivative​ is negative, it means that increasing *b* would decrease the error, so we need to increase *b* to minimize the error.

In gradient descent, we would then update *b* in the opposite direction of *the* derivative​ to reduce the cost function, hence the term "descent".

I hope you got the concepts clear, even if it's not clear, don't get intimidated, we have to progress, like we discussed in the beginning, we sometimes need to run before we learn to walk, so proceed with the coding by leveraging these two formulas and all the prior discussion we had until now.

<mark>Sure, I am attempting to code a basic Python code to translate this knowledge into a working code. Here is the Python code that computes m and b using the gradient descent algorithm we discussed.</mark>

```python
# Define the data points
X = [1, 2, 3]
Y = [1, 3, 2]
# Learning rate
learning_rate = 0.01
# Initial guess for m and b
m = 0.0
b = 0.0
# Number of iterations
iterations = 1000
# Function to update m and b
def update_m_b(m, b, X, Y, learning_rate):
    m_deriv = 0
    b_deriv = 0
    N = len(X)
    for i in range(N):
        # Calculate partial derivatives
        m_deriv += -2 * X[i] * (Y[i] - (m * X[i] + b))
        b_deriv += -2 * (Y[i] - (m * X[i] + b))
    # Update m and b
    m -= (m_deriv / N) * learning_rate
    b -= (b_deriv / N) * learning_rate
    return m, b
# Perform the iterations
for i in range(iterations):
    # Update m and b
    m, b = update_m_b(m, b, X, Y, learning_rate)
   
# Print the final values of m and b
print(f"\nFinal values after {iterations} iterations: m = {m:.4f}, b = {b:.4f}")
```

Let's go through the code step by step and explain the intuition, logic, and details behind each part.

```python
# Define the data points
X = [1, 2, 3]
Y = [1, 3, 2]
```

* This step defines the input data points. `X` represents the independent variable (input features), and `Y` represents the corresponding dependent variable (target values).
    
* In this example, we have three data points: (1, 1), (2, 3), and (3, 2).
    

```python
# Learning rate
learning_rate = 0.01
```

* The learning rate is a hyperparameter that controls the step size at which the parameters (m and b) are updated during each iteration of the gradient descent algorithm.
    
* A smaller learning rate means smaller updates to the parameters, while a larger learning rate means larger updates.
    
* The learning rate is set to 0.01 in this code.
    

```python
# Initial guess for m and b
m = 0.0
b = 0.0
```

* We start with an initial guess for the values of m (slope) and b (y-intercept) of the linear regression line.
    
* In this code, both m and b are initialized to 0.0
    

```python
# Number of iterations
iterations = 1000
```

* The number of iterations determines how many times the gradient descent algorithm will update the parameters (m and b) to minimize the cost function.
    
* In this code, the number of iterations is set to 1000.
    

```python
# Function to update m and b
def update_m_b(m, b, X, Y, learning_rate):
    m_deriv = 0
    b_deriv = 0
    N = len(X)
    for i in range(N):
        # Calculate partial derivatives
        m_deriv += -2 * X[i] * (Y[i] - (m * X[i] + b))
        b_deriv += -2 * (Y[i] - (m * X[i] + b))
    # Update m and b
    m -= (m_deriv / N) * learning_rate
    b -= (b_deriv / N) * learning_rate
    return m, b
```

* This function, `update_m_b`, is responsible for updating the values of m and b based on the gradient descent algorithm.
    
* It takes the current values of m, b, the input data points (X and Y), and the learning rate as parameters.
    
* Inside the function:
    
    * We initialize variables `m_deriv` and `b_deriv` to store the partial derivatives of the cost function with respect to m and b, respectively.
        
    * `N` is the number of data points.
        
    * We iterate over each data point using a `for` loop.
        
    * For each data point:
        
        * We calculate the partial derivative of the cost function with respect to m using the formula: `-2 * X[i] * (Y[i] - (m * X[i] + b))`.
            
        * We calculate the partial derivative of the cost function with respect to b using the formula: `-2 * (Y[i] - (m * X[i] + b))`.
            
        * These partial derivatives represent the rate of change of the cost function with respect to m and b, respectively.
            
    * After calculating the partial derivatives for all data points, we update the values of m and b using the gradient descent update rule:
        
        * `m` is updated by subtracting the average partial derivative with respect to m multiplied by the learning rate: `m -= (m_deriv / N) * learning_rate`.
            
        * `b` is updated by subtracting the average partial derivative with respect to b multiplied by the learning rate: `b -= (b_deriv / N) * learning_rate`.
            
    * Finally, the updated values of m and b are returned.
        

```python
# Perform the iterations
for i in range(iterations):
    # Update m and b
    m, b = update_m_b(m, b, X, Y, learning_rate)
```

* This loop performs the gradient descent iterations.
    
* For each iteration:
    
    * The `update_m_b` function is called with the current values of m, b, the input data points (X and Y), and the learning rate.
        
    * The function returns the updated values of m and b, which are assigned back to m and b, respectively.
        
* This process is repeated for the specified number of iterations.
    

```python
# Print the final values of m and b
print(f"\nFinal values after {iterations} iterations: m = {m:.4f}, b = {b:.4f}")
```

* After the iterations are completed, the final values of m and b are printed.
    
* The `:.4f` format specifier is used to display the values with 4 decimal places.
    

The intuition behind this code is to find the best-fitting linear regression line by minimizing the cost function using gradient descent. The cost function measures the difference between the predicted values (obtained using the current values of m and b) and the actual target values (Y). By iteratively updating the values of m and b based on the partial derivatives of the cost function, the algorithm gradually converges towards the optimal values that minimize the cost function and provide the best-fitting line.

The partial derivatives are calculated using the formulas derived from the cost function, which is the mean squared error (MSE) in this case. The MSE is the average of the squared differences between the predicted and actual values. By minimizing the MSE, we find the values of m and b that result in the least overall error.

The learning rate determines the size of the steps taken in each iteration. A smaller learning rate leads to slower convergence but can help avoid overshooting the minimum, while a larger learning rate can lead to faster convergence but may cause oscillations or divergence if set too high.

Overall, this code implements a basic gradient descent algorithm for linear regression, where the goal is to find the best-fitting line by iteratively updating the parameters (m and b) based on the gradients of the cost function until convergence is reached.

Visualization of the code at runtime.

Graph showing a snapshot of the work in progress and the final regression line.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1710195833748/4c53b2b8-aa2e-4cd2-a299-75e37e32703b.png align="center")

Graph showing cost function, m and b over iterations.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1710196005531/3512a49b-46ae-45bb-bf85-ea1ad6979cd9.png align="center")

Graph showing the cup shape of error with respect to m and b

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1710196051072/5e72df92-0878-4d6b-9315-94f08adfd8d0.png align="center")

### Day 8
